{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> FACTSET Hackathon </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Every file must be in root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The files shared by factset - Insofe assignment.xlsx which contains list of comapanies which are venture capitals and comapnies which are not venture capitals. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - Data Scarping\n",
    "Code file name - \n",
    "    - Non_VC_Home_&_Href_Scrape.ipynb [Containing all NON Venture capital websites and copany name]\n",
    "    - VC_Home_&_Href_Scrape.ipynb [Containing all Venture capital websites and copany name]\n",
    "\n",
    "* **The links shared for each company were used to scrape their websites using BeautifulSoup**\n",
    "    1. Data data includes tags present in website homepage , which are extracted from text present in t_tags of a website\n",
    "    2. All the hrefs froma all tags were extarcted for increasing our data , for which the site page information can be downloaded \n",
    "    \n",
    "* **After execuiton of codes two pickle dumps will be generated which contains all the feilds catpured while we scraped**\n",
    "    1. Data_NON_VC_Extracted_Scrape_1.pkl\n",
    "    2. Data_VC_Extracted_Scrape_1.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code file name - \n",
    "    - Problem_1_Base_Model.ipynb [Containing all base models build on data]\n",
    "Further models are build upon acheving baseline to improve our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocesing & Model development - Conatins solution of problem 1 & 2\n",
    "    - Problem_Solutions.ipynb [Final running file containing all data preprocessing steps and model's build on data scraped]\n",
    "Problem 1- model is build on the data which gives maximum accuracy of 76%\n",
    "Problem 2- Key words were extarcted for Venture capital by calculateing their imporantance score . \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development files for each stages \n",
    "- model_dev_v1.ipynb\n",
    "- model_dev_v2.ipynb\n",
    "- data_scraping_play.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre- Project research done before proceeeding with this project**\n",
    "#### **Doc - Research Work on Venture Capital.docx**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future scope -\n",
    "1. hrefs could be used for scraping ful website to inside size of courpus which would essenitlaly increase more information which can help gain more key words.\n",
    "2. With further more data availability Model fine tuning .\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
